{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and configuring the EfficientNet-B0 model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/50:   0%|          | 0/9 [00:00<?, ?it/s]C:\\Users\\Tuf\\AppData\\Local\\Temp\\ipykernel_3780\\727776225.py:124: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Epoch 1/50: 100%|██████████| 9/9 [00:11<00:00,  1.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1:\n",
      "Train Loss: 1.0109 | Train Accuracy: 0.0929\n",
      "Validation Loss: 1.9750 | Validation Accuracy: 0.0929\n",
      "✅ Model Saved! (Best Validation Loss Improved)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/50:   0%|          | 0/9 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from torchvision.models.efficientnet import EfficientNet_B0_Weights\n",
    "\n",
    "# Paths\n",
    "data_dir = \"../FBMM/test\"\n",
    "train_dir = os.path.join(data_dir, \"train\")\n",
    "val_dir = os.path.join(data_dir, \"val\")\n",
    "test_dir = os.path.join(data_dir, \"test\")\n",
    "model_save_path = \"./models/optimized_efficientnet_b0_emotion_model.pth\"\n",
    "\n",
    "# Configuration\n",
    "batch_size = 16\n",
    "num_epochs = 50\n",
    "initial_lr = 1e-4 \n",
    "weight_decay = 1e-4  \n",
    "num_classes = 7\n",
    "img_height, img_width = 224, 224\n",
    "seed = 42\n",
    "accumulation_steps = 2\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Emotion categories\n",
    "emotion_classes = [\"Anger\", \"Disgust\", \"Fear\", \"Happy\", \"Neutral\", \"Sad\", \"Surprise\"]\n",
    "\n",
    "# ✅ Use EfficientNet-B0 Weights\n",
    "weights = EfficientNet_B0_Weights.IMAGENET1K_V1\n",
    "\n",
    "# Data Augmentation & Normalization\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((img_height, img_width)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])  # ✅ Correct Normalization\n",
    "])\n",
    "\n",
    "# Load Datasets\n",
    "train_dataset = datasets.ImageFolder(root=train_dir, transform=transform)\n",
    "val_dataset = datasets.ImageFolder(root=val_dir, transform=transform)\n",
    "test_dataset = datasets.ImageFolder(root=test_dir, transform=transform)\n",
    "\n",
    "# Compute Class Weights\n",
    "def compute_class_weights(dataset, num_classes):\n",
    "    labels = np.array([label for _, label in dataset.samples])\n",
    "    class_counts = np.bincount(labels, minlength=num_classes)\n",
    "    class_weights = 1.0 / (class_counts + 1e-6)\n",
    "    class_weights /= class_weights.sum()\n",
    "    return torch.tensor(class_weights, dtype=torch.float32).to(device)\n",
    "\n",
    "class_weights = compute_class_weights(train_dataset, num_classes)\n",
    "\n",
    "# Data Loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=8, pin_memory=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=8, pin_memory=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=8, pin_memory=True)\n",
    "\n",
    "# ✅ Load Pretrained EfficientNet-B0 & Fine-Tune\n",
    "def load_model(num_classes):\n",
    "    print(\"Loading and configuring the EfficientNet-B0 model...\")\n",
    "\n",
    "    model = models.efficientnet_b0(weights=weights)  # ✅ Use EfficientNet-B0\n",
    "    model = model.to(memory_format=torch.channels_last)\n",
    "\n",
    "    # Freeze all layers initially\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    # Unlock last 20% of convolutional layers + classifier head\n",
    "    total_layers = len(list(model.features.children()))\n",
    "    fine_tune_layers = int(total_layers * 0.2)\n",
    "\n",
    "    for layer in list(model.features.children())[-fine_tune_layers:]:\n",
    "        for param in layer.parameters():\n",
    "            param.requires_grad = True\n",
    "\n",
    "    # Modify classifier head\n",
    "    model.classifier = nn.Sequential(\n",
    "        nn.Dropout(0.6),\n",
    "        nn.Linear(model.classifier[1].in_features, num_classes)\n",
    "    )\n",
    "\n",
    "    # Ensure classifier is trainable\n",
    "    for param in model.classifier.parameters():\n",
    "        param.requires_grad = True\n",
    "\n",
    "    return model.to(device)\n",
    "\n",
    "# Load model\n",
    "model = load_model(num_classes)\n",
    "\n",
    "# ✅ Fix: Use Label Smoothing to Prevent NaNs\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights, label_smoothing=0.1)\n",
    "\n",
    "# ✅ Fix: Reduce Learning Rate & Weight Decay\n",
    "optimizer = optim.AdamW(filter(lambda p: p.requires_grad, model.parameters()), lr=initial_lr, weight_decay=weight_decay)\n",
    "\n",
    "# ✅ Learning Rate Warm-Up & Scheduling\n",
    "scheduler = optim.lr_scheduler.OneCycleLR(optimizer, max_lr=initial_lr, epochs=num_epochs, steps_per_epoch=len(train_loader), pct_start=0.1)\n",
    "\n",
    "# ✅ Enable Mixed Precision Training\n",
    "scaler = torch.amp.GradScaler(device=\"cuda\")\n",
    "\n",
    "# Training Loop with Full Logging (Loss, Accuracy, Best Model)\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, scheduler, num_epochs, patience=7):\n",
    "    best_val_loss = np.inf\n",
    "    epochs_no_improve = 0\n",
    "\n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        model.train()\n",
    "        running_loss, correct, total = 0.0, 0, 0\n",
    "\n",
    "        for i, (images, labels) in enumerate(tqdm(train_loader, desc=f\"Epoch {epoch}/{num_epochs}\")):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            with torch.cuda.amp.autocast():\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels) / accumulation_steps\n",
    "\n",
    "            scaler.scale(loss).backward()\n",
    "\n",
    "            # ✅ Gradient Clipping to Prevent NaNs\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "\n",
    "            if (i + 1) % accumulation_steps == 0:\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "                optimizer.zero_grad()\n",
    "                scheduler.step()\n",
    "\n",
    "            running_loss += loss.item() * images.size(0)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "        train_loss = running_loss / total\n",
    "        train_acc = correct / total\n",
    "\n",
    "        # ✅ Validation Step\n",
    "        model.eval()\n",
    "        val_loss, val_correct, val_total = 0.0, 0, 0\n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item() * images.size(0)\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                val_correct += (predicted == labels).sum().item()\n",
    "                val_total += labels.size(0)\n",
    "\n",
    "        val_loss /= val_total\n",
    "        val_acc = val_correct / val_total\n",
    "\n",
    "        # ✅ Print Full Training Details\n",
    "        print(f\"\\nEpoch {epoch}:\")\n",
    "        print(f\"Train Loss: {train_loss:.4f} | Train Accuracy: {train_acc:.4f}\")\n",
    "        print(f\"Validation Loss: {val_loss:.4f} | Validation Accuracy: {val_acc:.4f}\")\n",
    "\n",
    "        # ✅ Save Best Model\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            torch.save(model.state_dict(), model_save_path)\n",
    "            print(\"✅ Model Saved! (Best Validation Loss Improved)\")\n",
    "            epochs_no_improve = 0\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "            if epochs_no_improve >= patience:\n",
    "                print(\"⏳ Early Stopping Triggered!\")\n",
    "                break\n",
    "\n",
    "# Train the model\n",
    "train_model(model, train_loader, val_loader, criterion, optimizer, scheduler, num_epochs)\n",
    "\n",
    "# Load best model for testing\n",
    "model.load_state_dict(torch.load(model_save_path))\n",
    "\n",
    "# Evaluate model\n",
    "def evaluate_model(model, test_loader):\n",
    "    model.eval()\n",
    "    correct, total = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "    accuracy = correct / total\n",
    "    print(f\"\\n🎯 Final Test Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "evaluate_model(model, test_loader)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DeepLearn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
