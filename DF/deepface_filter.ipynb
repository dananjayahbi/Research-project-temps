{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\Tuf\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "from deepface import DeepFace\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths\n",
    "DATASET_FOLDER = r\"C:\\Users\\Tuf\\Downloads\\Compressed\\AffectNet\"  # Change this to your actual dataset folder\n",
    "FILTERED_DATASET_FOLDER = \"Filtered_Dataset\"\n",
    "\n",
    "# Emotion categories detected by DeepFace\n",
    "EMOTION_CATEGORIES = [\"angry\", \"disgust\", \"fear\", \"happy\", \"sad\", \"surprise\", \"neutral\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Create the \"Filtered_Dataset\" folder with emotion subfolders\n",
    "def initialize_filtered_dataset():\n",
    "    if not os.path.exists(FILTERED_DATASET_FOLDER):\n",
    "        os.makedirs(FILTERED_DATASET_FOLDER)\n",
    "\n",
    "    for emotion in EMOTION_CATEGORIES:\n",
    "        emotion_folder = os.path.join(FILTERED_DATASET_FOLDER, emotion)\n",
    "        if not os.path.exists(emotion_folder):\n",
    "            os.makedirs(emotion_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Recursively find all image files in the dataset\n",
    "def get_all_images(dataset_path):\n",
    "    image_paths = []\n",
    "    for root, _, files in os.walk(dataset_path):\n",
    "        for file in files:\n",
    "            if file.lower().endswith((\".jpg\", \".jpeg\", \".png\")):\n",
    "                image_paths.append(os.path.join(root, file))\n",
    "    return image_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Process images and move them into categorized folders\n",
    "def process_images():\n",
    "    image_paths = get_all_images(DATASET_FOLDER)\n",
    "    print(f\"Found {len(image_paths)} images in the dataset.\")\n",
    "\n",
    "    for img_path in tqdm(image_paths, desc=\"Processing Images\"):\n",
    "        try:\n",
    "            # Analyze emotion with enforce_detection=False to prevent errors\n",
    "            result = DeepFace.analyze(img_path=img_path, actions=['emotion'], enforce_detection=False)\n",
    "\n",
    "            # Check if a face was detected\n",
    "            if not result or len(result) == 0:\n",
    "                print(f\"Skipping {img_path}: No face detected.\")\n",
    "                continue  # Skip this image\n",
    "\n",
    "            # Extract dominant emotion\n",
    "            dominant_emotion = result[0]['dominant_emotion'].lower()\n",
    "\n",
    "            # Ensure the emotion is one of the known categories\n",
    "            if dominant_emotion in EMOTION_CATEGORIES:\n",
    "                # Define target path\n",
    "                target_folder = os.path.join(FILTERED_DATASET_FOLDER, dominant_emotion)\n",
    "                target_path = os.path.join(target_folder, os.path.basename(img_path))\n",
    "\n",
    "                # Move image to corresponding folder\n",
    "                shutil.copy(img_path, target_path)\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {img_path}: {e}\")\n",
    "            continue  # Skip the current image and proceed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 41553 images in the dataset.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images: 100%|██████████| 41553/41553 [2:41:16<00:00,  4.29it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing completed. Images sorted into emotion folders.\n"
     ]
    }
   ],
   "source": [
    "# Run the script\n",
    "if __name__ == \"__main__\":\n",
    "    initialize_filtered_dataset()\n",
    "    process_images()\n",
    "    print(\"Processing completed. Images sorted into emotion folders.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
