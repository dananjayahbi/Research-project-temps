{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "import faiss\n",
    "from deepface import DeepFace\n",
    "from tqdm import tqdm\n",
    "from PIL import Image, UnidentifiedImageError\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… GPU is enabled for DeepFace!\n"
     ]
    }
   ],
   "source": [
    "# Force TensorFlow to use GPU\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "if physical_devices:\n",
    "    tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "    print(\"âœ… GPU is enabled for DeepFace!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define input and output directories\n",
    "INPUT_FOLDER = \"./unfiltered2\"\n",
    "OUTPUT_FOLDER = \"./unfiltered4\"\n",
    "\n",
    "# Emotion categories\n",
    "EMOTION_CLASSES = [\"anger\", \"contempt\", \"disgust\", \"fear\", \"happy\", \"neutral\", \"sad\", \"surprise\"]\n",
    "\n",
    "# DeepFace model for feature extraction\n",
    "DEEPFACE_MODEL = \"ArcFace\"  # Alternatives: \"Facenet\", \"ArcFace\", \"DeepID\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FAISS Parameters\n",
    "NUM_NEIGHBORS = 5  # Reduce from 10 to 5 (less aggressive similarity search)\n",
    "\n",
    "# DeepFace Verification Parameters\n",
    "SIMILARITY_THRESHOLD = 0.4  # Increase threshold (0.4-0.5 is good for more distinct images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure output structure exists\n",
    "def initialize_output_folders():\n",
    "    if not os.path.exists(OUTPUT_FOLDER):\n",
    "        os.makedirs(OUTPUT_FOLDER)\n",
    "\n",
    "    for emotion in EMOTION_CLASSES:\n",
    "        emotion_folder = os.path.join(OUTPUT_FOLDER, emotion)\n",
    "        if not os.path.exists(emotion_folder):\n",
    "            os.makedirs(emotion_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract deep learning-based feature embeddings\n",
    "def extract_embedding(image_path):\n",
    "    try:\n",
    "        embedding = DeepFace.represent(img_path=image_path, model_name=DEEPFACE_MODEL, enforce_detection=False)[0][\"embedding\"]\n",
    "        return np.array(embedding, dtype=np.float32)\n",
    "    except Exception as e:\n",
    "        print(f\"Skipping {image_path}: DeepFace error -> {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process images for a specific emotion category\n",
    "def process_emotion_class(emotion):\n",
    "    input_path = os.path.join(INPUT_FOLDER, emotion)\n",
    "    output_path = os.path.join(OUTPUT_FOLDER, emotion)\n",
    "\n",
    "    if not os.path.exists(input_path):\n",
    "        print(f\"Skipping {emotion}: No such folder in input dataset.\")\n",
    "        return\n",
    "\n",
    "    # Get all image paths in the category\n",
    "    image_paths = [\n",
    "        os.path.join(input_path, file) for file in os.listdir(input_path)\n",
    "        if file.lower().endswith((\".jpg\", \".jpeg\", \".png\"))\n",
    "    ]\n",
    "\n",
    "    if not image_paths:\n",
    "        print(f\"Skipping {emotion}: No images found.\")\n",
    "        return\n",
    "\n",
    "    print(f\"\\nðŸ”¹ Processing '{emotion}' folder ({len(image_paths)} images)...\")\n",
    "\n",
    "    # Step 1: Extract feature embeddings\n",
    "    image_embeddings = []\n",
    "    valid_image_paths = []\n",
    "\n",
    "    for img_path in tqdm(image_paths, desc=f\"Extracting embeddings ({emotion})\"):\n",
    "        embedding = extract_embedding(img_path)\n",
    "        if embedding is not None:\n",
    "            image_embeddings.append(embedding)\n",
    "            valid_image_paths.append(img_path)\n",
    "\n",
    "    if not valid_image_paths:\n",
    "        print(f\"Skipping '{emotion}': No valid images after feature extraction.\")\n",
    "        return\n",
    "\n",
    "    image_embeddings = np.array(image_embeddings)\n",
    "\n",
    "    # Step 2: Build FAISS index for fast nearest neighbor search\n",
    "    dimension = image_embeddings.shape[1]\n",
    "    index = faiss.IndexFlatL2(dimension)\n",
    "    index.add(image_embeddings)\n",
    "\n",
    "    # Step 3: Identify distinct images\n",
    "    unique_images = []\n",
    "    checked_images = set()\n",
    "\n",
    "    print(f\"Identifying distinct images for '{emotion}'...\")\n",
    "\n",
    "    for i, img_path in tqdm(enumerate(valid_image_paths), total=len(valid_image_paths), desc=f\"Verifying ({emotion})\"):\n",
    "        if img_path in checked_images:\n",
    "            continue\n",
    "\n",
    "        # Find similar images (reduced from 10 to NUM_NEIGHBORS to improve distinct detection)\n",
    "        distances, indices = index.search(np.array([image_embeddings[i]]), k=NUM_NEIGHBORS)\n",
    "\n",
    "        is_duplicate = False\n",
    "        for j in indices[0][1:]:  # Skip self-match\n",
    "            if valid_image_paths[j] in checked_images:\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                # Use DeepFace for final verification\n",
    "                result = DeepFace.verify(img1_path=img_path, img2_path=valid_image_paths[j], enforce_detection=False)\n",
    "                similarity_score = result.get(\"distance\", 1.0)  # Lower is more similar\n",
    "\n",
    "                if similarity_score < SIMILARITY_THRESHOLD:\n",
    "                    is_duplicate = True\n",
    "                    break  # Stop if duplicate found\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Skipping {img_path}: DeepFace verification error -> {e}\")\n",
    "                continue\n",
    "\n",
    "        # If not duplicate, save it\n",
    "        if not is_duplicate:\n",
    "            unique_images.append(img_path)\n",
    "            shutil.copy(img_path, os.path.join(output_path, os.path.basename(img_path)))\n",
    "\n",
    "        checked_images.add(img_path)\n",
    "\n",
    "    print(f\"âœ… Processing completed for '{emotion}'. Found {len(unique_images)} distinct images.\")\n",
    "    print(f\"ðŸ“‚ Distinct images saved in: {output_path}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ”¹ Processing 'anger' folder (15729 images)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings (anger):   0%|          | 0/15729 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25-01-18 12:45:47 - arcface_weights.h5 will be downloaded to C:\\Users\\Tuf\\.deepface/weights\\arcface_weights.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://github.com/serengil/deepface_models/releases/download/v1.0/arcface_weights.h5\n",
      "To: C:\\Users\\Tuf\\.deepface\\weights\\arcface_weights.h5\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 137M/137M [00:29<00:00, 4.58MB/s]\n",
      "Extracting embeddings (anger): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15729/15729 [34:02<00:00,  7.70it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identifying distinct images for 'anger'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Verifying (anger): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15729/15729 [40:08<00:00,  6.53it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Processing completed for 'anger'. Found 10634 distinct images.\n",
      "ðŸ“‚ Distinct images saved in: ./unfiltered4\\anger\n",
      "\n",
      "\n",
      "ðŸ”¹ Processing 'contempt' folder (17006 images)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings (contempt): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17006/17006 [34:53<00:00,  8.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identifying distinct images for 'contempt'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Verifying (contempt): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17006/17006 [38:16<00:00,  7.41it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Processing completed for 'contempt'. Found 9235 distinct images.\n",
      "ðŸ“‚ Distinct images saved in: ./unfiltered4\\contempt\n",
      "\n",
      "\n",
      "ðŸ”¹ Processing 'disgust' folder (16149 images)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings (disgust): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16149/16149 [30:34<00:00,  8.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identifying distinct images for 'disgust'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Verifying (disgust): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16149/16149 [35:01<00:00,  7.68it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Processing completed for 'disgust'. Found 8651 distinct images.\n",
      "ðŸ“‚ Distinct images saved in: ./unfiltered4\\disgust\n",
      "\n",
      "\n",
      "ðŸ”¹ Processing 'fear' folder (15203 images)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings (fear): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15203/15203 [34:34<00:00,  7.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identifying distinct images for 'fear'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Verifying (fear): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15203/15203 [46:56<00:00,  5.40it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Processing completed for 'fear'. Found 9445 distinct images.\n",
      "ðŸ“‚ Distinct images saved in: ./unfiltered4\\fear\n",
      "\n",
      "\n",
      "ðŸ”¹ Processing 'happy' folder (16715 images)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings (happy): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16715/16715 [36:51<00:00,  7.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identifying distinct images for 'happy'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Verifying (happy): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16715/16715 [58:39<00:00,  4.75it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Processing completed for 'happy'. Found 13190 distinct images.\n",
      "ðŸ“‚ Distinct images saved in: ./unfiltered4\\happy\n",
      "\n",
      "\n",
      "ðŸ”¹ Processing 'neutral' folder (16710 images)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings (neutral): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16710/16710 [35:23<00:00,  7.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identifying distinct images for 'neutral'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Verifying (neutral): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16710/16710 [51:06<00:00,  5.45it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Processing completed for 'neutral'. Found 12380 distinct images.\n",
      "ðŸ“‚ Distinct images saved in: ./unfiltered4\\neutral\n",
      "\n",
      "\n",
      "ðŸ”¹ Processing 'sad' folder (15014 images)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings (sad): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15014/15014 [30:51<00:00,  8.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identifying distinct images for 'sad'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Verifying (sad): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15014/15014 [39:01<00:00,  6.41it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Processing completed for 'sad'. Found 10638 distinct images.\n",
      "ðŸ“‚ Distinct images saved in: ./unfiltered4\\sad\n",
      "\n",
      "\n",
      "ðŸ”¹ Processing 'surprise' folder (16109 images)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings (surprise): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16109/16109 [34:36<00:00,  7.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identifying distinct images for 'surprise'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Verifying (surprise): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16109/16109 [47:27<00:00,  5.66it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Processing completed for 'surprise'. Found 9479 distinct images.\n",
      "ðŸ“‚ Distinct images saved in: ./unfiltered4\\surprise\n",
      "\n",
      "ðŸŽ‰ All categories processed successfully!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Run the script\n",
    "if __name__ == \"__main__\":\n",
    "    initialize_output_folders()\n",
    "\n",
    "    # Process each emotion category separately\n",
    "    for emotion in EMOTION_CLASSES:\n",
    "        process_emotion_class(emotion)\n",
    "\n",
    "    print(\"ðŸŽ‰ All categories processed successfully!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Testings",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
