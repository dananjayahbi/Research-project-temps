{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "import imagehash\n",
    "from PIL import Image, UnidentifiedImageError\n",
    "from collections import defaultdict\n",
    "from deepface import DeepFace\n",
    "from tqdm import tqdm\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import cv2\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ GPU is enabled for DeepFace!\n"
     ]
    }
   ],
   "source": [
    "# Force TensorFlow to use GPU\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "if physical_devices:\n",
    "    tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "    print(\"✅ GPU is enabled for DeepFace!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define input and output directories\n",
    "INPUT_FOLDER = \"./temp/input\"\n",
    "OUTPUT_FOLDER = \"./temp/output\"\n",
    "\n",
    "# Ensure output folder exists\n",
    "if not os.path.exists(OUTPUT_FOLDER):\n",
    "    os.makedirs(OUTPUT_FOLDER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate perceptual hash (PHash)\n",
    "def calculate_phash(image_path):\n",
    "    try:\n",
    "        img = Image.open(image_path).convert(\"L\")  # Convert to grayscale\n",
    "        return str(imagehash.phash(img))  # Generate hash\n",
    "    except UnidentifiedImageError:\n",
    "        print(f\"Skipping {image_path}: Unreadable image format.\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error hashing {image_path}: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 50 images to find distinct ones...\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Group images by PHash (fast pre-filtering)\n",
    "image_hash_groups = defaultdict(list)  # Dictionary to store images per hash\n",
    "\n",
    "image_paths = [\n",
    "    os.path.join(INPUT_FOLDER, file) for file in os.listdir(INPUT_FOLDER)\n",
    "    if file.lower().endswith((\".jpg\", \".jpeg\", \".png\"))\n",
    "]\n",
    "\n",
    "print(f\"Processing {len(image_paths)} images to find distinct ones...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to verify duplicates within a group using DeepFace\n",
    "def verify_duplicates_in_group(group, unique_images, lock):\n",
    "    for img_path in group:\n",
    "        is_duplicate = False\n",
    "\n",
    "        # Check if OpenCV can read the image\n",
    "        if cv2.imread(img_path) is None:\n",
    "            print(f\"Skipping {img_path}: Corrupted image.\")\n",
    "            continue\n",
    "\n",
    "        # Compare with already confirmed unique images\n",
    "        for unique_img in unique_images:\n",
    "            try:\n",
    "                # Use DeepFace for precise verification with enforce_detection=False\n",
    "                result = DeepFace.verify(img1_path=img_path, img2_path=unique_img, enforce_detection=False)\n",
    "\n",
    "                # If DeepFace considers them identical, mark as duplicate\n",
    "                if result.get(\"verified\", False):\n",
    "                    is_duplicate = True\n",
    "                    break  # No need to check further\n",
    "\n",
    "            except Exception as e:\n",
    "                continue  # Skip this image if error occurs\n",
    "\n",
    "        # If unique, add to final set\n",
    "        if not is_duplicate:\n",
    "            with lock:\n",
    "                unique_images.append(img_path)\n",
    "                shutil.copy(img_path, os.path.join(OUTPUT_FOLDER, os.path.basename(img_path)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 50 images to find distinct ones...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hashing images: 100%|██████████| 50/50 [00:00<00:00, 460.83it/s]\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Group images by PHash (fast pre-filtering)\n",
    "image_hash_groups = defaultdict(list)  # Dictionary to store images per hash\n",
    "\n",
    "image_paths = [\n",
    "    os.path.join(INPUT_FOLDER, file) for file in os.listdir(INPUT_FOLDER)\n",
    "    if file.lower().endswith((\".jpg\", \".jpeg\", \".png\"))\n",
    "]\n",
    "\n",
    "print(f\"Processing {len(image_paths)} images to find distinct ones...\")\n",
    "\n",
    "for img_path in tqdm(image_paths, desc=\"Hashing images\"):\n",
    "    phash = calculate_phash(img_path)\n",
    "    if phash:\n",
    "        image_hash_groups[phash].append(img_path)  # Group images by their hash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Verifying groups: 100%|██████████| 44/44 [00:25<00:00,  1.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing complete. Found 17 distinct images.\n",
      "Distinct images saved in: ./temp/output\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Verify duplicates within each hash group using multithreading\n",
    "unique_images = []  # Shared list for unique images\n",
    "from threading import Lock  # To avoid race conditions in shared list access\n",
    "lock = Lock()\n",
    "\n",
    "with ThreadPoolExecutor() as executor:\n",
    "    futures = [\n",
    "        executor.submit(verify_duplicates_in_group, group, unique_images, lock)\n",
    "        for group in image_hash_groups.values()\n",
    "    ]\n",
    "\n",
    "    for future in tqdm(futures, desc=\"Verifying groups\"):\n",
    "        future.result()  # Wait for all threads to complete\n",
    "\n",
    "print(f\"Processing complete. Found {len(unique_images)} distinct images.\")\n",
    "print(f\"Distinct images saved in: {OUTPUT_FOLDER}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Testings",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
