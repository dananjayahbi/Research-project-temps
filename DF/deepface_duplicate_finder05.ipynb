{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "import faiss\n",
    "from deepface import DeepFace\n",
    "from tqdm import tqdm\n",
    "from PIL import Image, UnidentifiedImageError\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… GPU is enabled for DeepFace!\n"
     ]
    }
   ],
   "source": [
    "# Force TensorFlow to use GPU\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "if physical_devices:\n",
    "    tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "    print(\"âœ… GPU is enabled for DeepFace!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define input and output directories\n",
    "INPUT_FOLDER = \"./unfiltered2\"\n",
    "OUTPUT_FOLDER = \"./unfiltered3\"\n",
    "\n",
    "# Emotion categories (Subfolder names)\n",
    "EMOTION_CLASSES = [\"anger\", \"contempt\", \"disgust\", \"fear\", \"happy\", \"neutral\", \"sad\", \"surprise\"]\n",
    "\n",
    "# DeepFace model for feature extraction\n",
    "DEEPFACE_MODEL = \"VGG-Face\"  # Alternative: \"ArcFace\", \"Facenet\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure output structure exists\n",
    "def initialize_output_folders():\n",
    "    if not os.path.exists(OUTPUT_FOLDER):\n",
    "        os.makedirs(OUTPUT_FOLDER)\n",
    "    \n",
    "    for emotion in EMOTION_CLASSES:\n",
    "        emotion_folder = os.path.join(OUTPUT_FOLDER, emotion)\n",
    "        if not os.path.exists(emotion_folder):\n",
    "            os.makedirs(emotion_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract deep learning-based feature embeddings\n",
    "def extract_embedding(image_path):\n",
    "    try:\n",
    "        embedding = DeepFace.represent(img_path=image_path, model_name=DEEPFACE_MODEL, enforce_detection=False)[0][\"embedding\"]\n",
    "        return np.array(embedding, dtype=np.float32)\n",
    "    except Exception as e:\n",
    "        print(f\"Skipping {image_path}: DeepFace error -> {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process images for a specific emotion category\n",
    "def process_emotion_class(emotion):\n",
    "    input_path = os.path.join(INPUT_FOLDER, emotion)\n",
    "    output_path = os.path.join(OUTPUT_FOLDER, emotion)\n",
    "\n",
    "    # Ensure the input category folder exists\n",
    "    if not os.path.exists(input_path):\n",
    "        print(f\"Skipping {emotion}: No such folder in input dataset.\")\n",
    "        return\n",
    "\n",
    "    # Get all image paths in the category\n",
    "    image_paths = [\n",
    "        os.path.join(input_path, file) for file in os.listdir(input_path)\n",
    "        if file.lower().endswith((\".jpg\", \".jpeg\", \".png\"))\n",
    "    ]\n",
    "\n",
    "    if not image_paths:\n",
    "        print(f\"Skipping {emotion}: No images found.\")\n",
    "        return\n",
    "\n",
    "    print(f\"\\nðŸ”¹ Processing '{emotion}' folder ({len(image_paths)} images)...\")\n",
    "\n",
    "    # Step 1: Extract feature embeddings\n",
    "    image_embeddings = []\n",
    "    valid_image_paths = []\n",
    "\n",
    "    for img_path in tqdm(image_paths, desc=f\"Extracting embeddings ({emotion})\"):\n",
    "        embedding = extract_embedding(img_path)\n",
    "        if embedding is not None:\n",
    "            image_embeddings.append(embedding)\n",
    "            valid_image_paths.append(img_path)\n",
    "\n",
    "    if not valid_image_paths:\n",
    "        print(f\"Skipping '{emotion}': No valid images after feature extraction.\")\n",
    "        return\n",
    "\n",
    "    image_embeddings = np.array(image_embeddings)\n",
    "\n",
    "    # Step 2: Build FAISS index for fast nearest neighbor search\n",
    "    dimension = image_embeddings.shape[1]  # Get embedding size\n",
    "    index = faiss.IndexFlatL2(dimension)  # L2 distance for similarity search\n",
    "    index.add(image_embeddings)  # Add all image embeddings\n",
    "\n",
    "    # Step 3: Identify distinct images\n",
    "    unique_images = []\n",
    "    checked_images = set()\n",
    "\n",
    "    print(f\"Identifying distinct images for '{emotion}'...\")\n",
    "\n",
    "    for i, img_path in tqdm(enumerate(valid_image_paths), total=len(valid_image_paths), desc=f\"Verifying ({emotion})\"):\n",
    "        if img_path in checked_images:\n",
    "            continue\n",
    "\n",
    "        # Find similar images\n",
    "        distances, indices = index.search(np.array([image_embeddings[i]]), k=10)  # Get top-10 nearest images\n",
    "\n",
    "        is_duplicate = False\n",
    "        for j in indices[0][1:]:  # Skip self-match\n",
    "            if valid_image_paths[j] in checked_images:\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                # Use DeepFace for final verification\n",
    "                result = DeepFace.verify(img1_path=img_path, img2_path=valid_image_paths[j], enforce_detection=False)\n",
    "                if result.get(\"verified\", False):\n",
    "                    is_duplicate = True\n",
    "                    break  # Stop if duplicate found\n",
    "            except Exception as e:\n",
    "                print(f\"Skipping {img_path}: DeepFace verification error -> {e}\")\n",
    "                continue\n",
    "\n",
    "        # If not duplicate, save it\n",
    "        if not is_duplicate:\n",
    "            unique_images.append(img_path)\n",
    "            shutil.copy(img_path, os.path.join(output_path, os.path.basename(img_path)))\n",
    "\n",
    "        checked_images.add(img_path)\n",
    "\n",
    "    print(f\"âœ… Processing completed for '{emotion}'. Found {len(unique_images)} distinct images.\")\n",
    "    print(f\"ðŸ“‚ Distinct images saved in: {output_path}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ”¹ Processing 'anger' folder (15729 images)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings (anger): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15729/15729 [15:15<00:00, 17.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identifying distinct images for 'anger'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Verifying (anger): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15729/15729 [34:01<00:00,  7.70it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Processing completed for 'anger'. Found 1568 distinct images.\n",
      "ðŸ“‚ Distinct images saved in: ./unfiltered3\\anger\n",
      "\n",
      "\n",
      "ðŸ”¹ Processing 'contempt' folder (17006 images)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings (contempt): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17006/17006 [21:00<00:00, 13.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identifying distinct images for 'contempt'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Verifying (contempt): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17006/17006 [39:01<00:00,  7.26it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Processing completed for 'contempt'. Found 1826 distinct images.\n",
      "ðŸ“‚ Distinct images saved in: ./unfiltered3\\contempt\n",
      "\n",
      "\n",
      "ðŸ”¹ Processing 'disgust' folder (16149 images)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings (disgust): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16149/16149 [15:41<00:00, 17.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identifying distinct images for 'disgust'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Verifying (disgust): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16149/16149 [33:17<00:00,  8.09it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Processing completed for 'disgust'. Found 1714 distinct images.\n",
      "ðŸ“‚ Distinct images saved in: ./unfiltered3\\disgust\n",
      "\n",
      "\n",
      "ðŸ”¹ Processing 'fear' folder (15203 images)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings (fear): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15203/15203 [15:52<00:00, 15.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identifying distinct images for 'fear'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Verifying (fear): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15203/15203 [32:17<00:00,  7.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Processing completed for 'fear'. Found 1359 distinct images.\n",
      "ðŸ“‚ Distinct images saved in: ./unfiltered3\\fear\n",
      "\n",
      "\n",
      "ðŸ”¹ Processing 'happy' folder (16715 images)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings (happy): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16715/16715 [17:33<00:00, 15.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identifying distinct images for 'happy'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Verifying (happy): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16715/16715 [35:20<00:00,  7.88it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Processing completed for 'happy'. Found 1454 distinct images.\n",
      "ðŸ“‚ Distinct images saved in: ./unfiltered3\\happy\n",
      "\n",
      "\n",
      "ðŸ”¹ Processing 'neutral' folder (16710 images)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings (neutral): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16710/16710 [17:27<00:00, 15.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identifying distinct images for 'neutral'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Verifying (neutral): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16710/16710 [36:59<00:00,  7.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Processing completed for 'neutral'. Found 1547 distinct images.\n",
      "ðŸ“‚ Distinct images saved in: ./unfiltered3\\neutral\n",
      "\n",
      "\n",
      "ðŸ”¹ Processing 'sad' folder (15014 images)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings (sad): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15014/15014 [14:29<00:00, 17.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identifying distinct images for 'sad'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Verifying (sad): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15014/15014 [29:52<00:00,  8.38it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Processing completed for 'sad'. Found 1419 distinct images.\n",
      "ðŸ“‚ Distinct images saved in: ./unfiltered3\\sad\n",
      "\n",
      "\n",
      "ðŸ”¹ Processing 'surprise' folder (16109 images)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings (surprise): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16109/16109 [17:13<00:00, 15.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identifying distinct images for 'surprise'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Verifying (surprise): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16109/16109 [35:10<00:00,  7.63it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Processing completed for 'surprise'. Found 1132 distinct images.\n",
      "ðŸ“‚ Distinct images saved in: ./unfiltered3\\surprise\n",
      "\n",
      "ðŸŽ‰ All categories processed successfully!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Run the script\n",
    "if __name__ == \"__main__\":\n",
    "    initialize_output_folders()\n",
    "\n",
    "    # Process each emotion category separately\n",
    "    for emotion in EMOTION_CLASSES:\n",
    "        process_emotion_class(emotion)\n",
    "\n",
    "    print(\"ðŸŽ‰ All categories processed successfully!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Testings",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
