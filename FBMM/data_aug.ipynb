{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import uuid\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚ö†Ô∏è Set these paths manually before running\n",
    "DATASET_FOLDER = \"./Unsplitted_Ready_Sets/set_01_raw_class_balanced\"  # The original dataset folder with 7 classes\n",
    "AUGMENTED_FOLDER = \"./Unsplitted_Ready_Sets/set_01_class_balanced_augs_applied\"  # Where augmented images will be stored\n",
    "\n",
    "# Emotion categories (Folder names must match)\n",
    "EMOTION_CATEGORIES = [\"Angry\", \"Disgust\", \"Fear\", \"Happy\", \"Neutral\", \"Sad\", \"Surprise\"]\n",
    "\n",
    "# Set augmentation parameters\n",
    "IMAGE_SIZE = (260, 260)  # Target image size\n",
    "IMAGES_PER_CLASS = 7382  # Number of images per class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define augmentation transformations\n",
    "def get_augmentations():\n",
    "    return [\n",
    "        # First augmentation: Horizontal Flip + Random Crop\n",
    "        transforms.Compose([\n",
    "            transforms.RandomHorizontalFlip(p=1.0),\n",
    "            transforms.RandomResizedCrop(IMAGE_SIZE, scale=(0.9, 1.0)),\n",
    "            transforms.ToTensor(),\n",
    "            # transforms.Normalize(mean=[0.5], std=[0.5])\n",
    "        ]),\n",
    "        # Second augmentation: Rotation + Brightness/Contrast Adjustment\n",
    "        transforms.Compose([\n",
    "            transforms.RandomRotation(degrees=15),\n",
    "            transforms.ColorJitter(brightness=0.1, contrast=0.1),\n",
    "            transforms.ToTensor(),\n",
    "            # transforms.Normalize(mean=[0.5], std=[0.5])\n",
    "        ]),\n",
    "        # Third augmentation: Gaussian Noise + Color Jittering\n",
    "        transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Lambda(lambda x: x + torch.randn_like(x) * 0.02),\n",
    "            transforms.ColorJitter(saturation=0.1),\n",
    "            # transforms.Normalize(mean=[0.5], std=[0.5])\n",
    "        ])\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Create the \"AUGMENTED_FOLDER\" with emotion subfolders\n",
    "def initialize_augmented_dataset():\n",
    "    if not os.path.exists(AUGMENTED_FOLDER):\n",
    "        os.makedirs(AUGMENTED_FOLDER)\n",
    "\n",
    "    for emotion in EMOTION_CATEGORIES:\n",
    "        emotion_folder = os.path.join(AUGMENTED_FOLDER, emotion)\n",
    "        if not os.path.exists(emotion_folder):\n",
    "            os.makedirs(emotion_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Apply augmentations to images\n",
    "def augment_class(emotion_category):\n",
    "    source_folder = os.path.join(DATASET_FOLDER, emotion_category)\n",
    "    target_folder = os.path.join(AUGMENTED_FOLDER, emotion_category)\n",
    "\n",
    "    # Check if source folder exists\n",
    "    if not os.path.exists(source_folder):\n",
    "        print(f\"‚ùå Skipping {emotion_category}: No such folder in dataset.\")\n",
    "        return\n",
    "\n",
    "    # Get all images in the class folder\n",
    "    image_paths = [\n",
    "        os.path.join(source_folder, file) for file in sorted(os.listdir(source_folder))\n",
    "        if file.lower().endswith((\".jpg\", \".jpeg\", \".png\"))\n",
    "    ]\n",
    "\n",
    "    # Get transformations\n",
    "    augmentations = get_augmentations()\n",
    "\n",
    "    print(f\"üìÇ Augmenting {emotion_category}...\")\n",
    "\n",
    "    # Step 2.1: Process each image with all augmentations\n",
    "    with tqdm(total=len(image_paths) * 3, desc=f\"Augmenting {emotion_category}\") as pbar:\n",
    "        for img_path in image_paths:\n",
    "            try:\n",
    "                img = Image.open(img_path).convert(\"RGB\")  # Keep color for augmentation\n",
    "\n",
    "                for j, transform in enumerate(augmentations):\n",
    "                    augmented_img = transform(img)\n",
    "                    augmented_img = transforms.ToPILImage()(augmented_img)\n",
    "\n",
    "                    # Ensure unique filenames\n",
    "                    unique_name = f\"aug_{j}_{str(uuid.uuid4())[:8]}_{os.path.basename(img_path)}\"\n",
    "                    target_path = os.path.join(target_folder, unique_name)\n",
    "                    augmented_img.save(target_path)\n",
    "\n",
    "                    pbar.update(1)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"‚ö†Ô∏è Error processing {img_path}: {e}\")\n",
    "                pbar.update(1)\n",
    "\n",
    "    print(f\"‚úÖ Augmentation completed for {emotion_category}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÇ Augmenting Angry...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Augmenting Angry: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 22146/22146 [12:45<00:00, 28.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Augmentation completed for Angry.\n",
      "üìÇ Augmenting Disgust...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Augmenting Disgust: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 22146/22146 [12:29<00:00, 29.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Augmentation completed for Disgust.\n",
      "üìÇ Augmenting Fear...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Augmenting Fear: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 22146/22146 [12:49<00:00, 28.78it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Augmentation completed for Fear.\n",
      "üìÇ Augmenting Happy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Augmenting Happy: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 22146/22146 [14:59<00:00, 24.63it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Augmentation completed for Happy.\n",
      "üìÇ Augmenting Neutral...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Augmenting Neutral: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 22146/22146 [15:02<00:00, 24.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Augmentation completed for Neutral.\n",
      "üìÇ Augmenting Sad...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Augmenting Sad: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 22146/22146 [12:08<00:00, 30.42it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Augmentation completed for Sad.\n",
      "üìÇ Augmenting Surprise...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Augmenting Surprise: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 22146/22146 [15:23<00:00, 23.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Augmentation completed for Surprise.\n",
      "\n",
      "‚úÖ Dataset augmentation completed! Augmented images are stored in: ./Unsplitted_Ready_Sets/set_01_class_balanced_augs_applied\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Run the augmentation process\n",
    "if __name__ == \"__main__\":\n",
    "    initialize_augmented_dataset()\n",
    "\n",
    "    # Process each emotion category\n",
    "    for category in EMOTION_CATEGORIES:\n",
    "        augment_class(category)\n",
    "\n",
    "    print(f\"\\n‚úÖ Dataset augmentation completed! Augmented images are stored in: {AUGMENTED_FOLDER}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DeepLearn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
